{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from joblib import dump, load\n",
    "import geopandas as gpd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laia/anaconda3/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator StandardScaler from version 1.1.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/laia/anaconda3/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator Pipeline from version 1.1.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/laia/anaconda3/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator GridSearchCV from version 1.1.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipe_rf = load('./models/cv_rf.joblib') \n",
    "pipe_lr = load('./models/cv_lr.joblib') \n",
    "pipe_xgb = load('./models/cv_xgb.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = gpd.read_file( \"./data/train_data_final.geojson\")\n",
    "test =  gpd.read_file(\"./data/test_data_final.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NDVI_2000', 'NDVI_2001', 'NDVI_2002', 'NDVI_2003', 'NDVI_2004',\n",
       "       'NDVI_2005', 'NDVI_2006', 'NDVI_2007', 'NDVI_2008', 'NDVI_2009',\n",
       "       'NDVI_2010', 'NDVI_2011', 'NDVI_2012', 'NDVI_2013', 'NDVI_2014',\n",
       "       'NDVI_2015', 'NDVI_2016', 'NDVI_2017', 'NDVI_2018', 'NDVI_2019',\n",
       "       'NDVI_2020', 'id', 'label', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.loc[:,'NDVI_2000':'NDVI_2019']\n",
    "y = train['label']\n",
    "X_test = test.loc[:,'NDVI_2000':'NDVI_2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_rf = pipe_rf.best_estimator_\n",
    "best_model_lr = pipe_lr.best_estimator_\n",
    "best_model_xgb = pipe_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report de RF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.59      0.65       877\n",
      "           1       0.88      0.91      0.89       900\n",
      "           2       0.70      0.81      0.75       859\n",
      "\n",
      "    accuracy                           0.77      2636\n",
      "   macro avg       0.77      0.77      0.76      2636\n",
      "weighted avg       0.77      0.77      0.76      2636\n",
      "\n",
      "\n",
      "\n",
      "Classification report de reg logística\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.49      0.52       877\n",
      "           1       0.77      0.77      0.77       900\n",
      "           2       0.67      0.75      0.70       859\n",
      "\n",
      "    accuracy                           0.67      2636\n",
      "   macro avg       0.67      0.67      0.67      2636\n",
      "weighted avg       0.67      0.67      0.67      2636\n",
      "\n",
      "\n",
      "\n",
      "Classification report de XGBoost\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report de RF\")\n",
    "print(classification_report(test['label'],best_model_rf.predict(X_test)))\n",
    "print(\"\\n\")\n",
    "print(\"Classification report de reg logística\")\n",
    "print(classification_report(test['label'],best_model_lr.predict(X_test)))\n",
    "print(\"\\n\")\n",
    "print(\"Classification report de XGBoost\")\n",
    "#print(classification_report(test['label.x'],best_model_xgb.predict(X_test)))\n",
    "#print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['predictions_rf'] = best_model_rf.predict(X_test)\n",
    "test['predictions_lr'] = best_model_lr.predict(X_test)\n",
    "#test['predictions_xgb'] = best_model_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_file(\"data/test_predictions.geojson\", driver='GeoJSON')\n",
    "#Para GEE en .shp\n",
    "#test.to_file(\"data/preds/test_predictions.shp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exporto_clasif(modelo, nombre):\n",
    "    report_data = classification_report(test['label'],modelo.predict(X_test), output_dict=True)\n",
    "    dataframe = pd.DataFrame.from_dict(report_data).reset_index()\n",
    "    dataframe = dataframe.rename(columns={\"index\": \"metric\"})\n",
    "    \n",
    "    dataframe.to_csv('data/preds/classification_report_'+nombre+'.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "exporto_clasif(best_model_rf, 'random_forest')\n",
    "exporto_clasif(best_model_lr, 'reg_log')\n",
    "#exporto_clasif(best_model_xgb, 'xgb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
