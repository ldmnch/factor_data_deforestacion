{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_xKTfvpIzf8g"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from joblib import dump, load\n",
    "import geopandas as gpd\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zfN_yTy1z7Q8"
   },
   "outputs": [],
   "source": [
    "train = gpd.read_file( \"./data/train_data_final.geojson\")\n",
    "test =  gpd.read_file(\"./data/test_data_final.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7ooSD3Dk0yOY"
   },
   "outputs": [],
   "source": [
    "X = train.loc[:,'NDVI_2000':'NDVI_2019']\n",
    "y = train['label']\n",
    "X_test = test.loc[:,'NDVI_2000':'NDVI_2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDVI_2000</th>\n",
       "      <th>NDVI_2001</th>\n",
       "      <th>NDVI_2002</th>\n",
       "      <th>NDVI_2003</th>\n",
       "      <th>NDVI_2004</th>\n",
       "      <th>NDVI_2005</th>\n",
       "      <th>NDVI_2006</th>\n",
       "      <th>NDVI_2007</th>\n",
       "      <th>NDVI_2008</th>\n",
       "      <th>NDVI_2009</th>\n",
       "      <th>NDVI_2010</th>\n",
       "      <th>NDVI_2011</th>\n",
       "      <th>NDVI_2012</th>\n",
       "      <th>NDVI_2013</th>\n",
       "      <th>NDVI_2014</th>\n",
       "      <th>NDVI_2015</th>\n",
       "      <th>NDVI_2016</th>\n",
       "      <th>NDVI_2017</th>\n",
       "      <th>NDVI_2018</th>\n",
       "      <th>NDVI_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.520041</td>\n",
       "      <td>0.441816</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.567321</td>\n",
       "      <td>0.520761</td>\n",
       "      <td>0.598021</td>\n",
       "      <td>0.576371</td>\n",
       "      <td>0.529067</td>\n",
       "      <td>0.572539</td>\n",
       "      <td>0.531320</td>\n",
       "      <td>0.536898</td>\n",
       "      <td>0.606290</td>\n",
       "      <td>0.565013</td>\n",
       "      <td>0.535213</td>\n",
       "      <td>0.413766</td>\n",
       "      <td>0.466405</td>\n",
       "      <td>0.614485</td>\n",
       "      <td>0.616926</td>\n",
       "      <td>0.554876</td>\n",
       "      <td>0.634924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.255850</td>\n",
       "      <td>0.251777</td>\n",
       "      <td>0.233125</td>\n",
       "      <td>0.240606</td>\n",
       "      <td>0.259371</td>\n",
       "      <td>0.267388</td>\n",
       "      <td>0.256132</td>\n",
       "      <td>0.301995</td>\n",
       "      <td>0.317402</td>\n",
       "      <td>0.264193</td>\n",
       "      <td>0.283245</td>\n",
       "      <td>0.275672</td>\n",
       "      <td>0.302882</td>\n",
       "      <td>0.268858</td>\n",
       "      <td>0.267923</td>\n",
       "      <td>0.286384</td>\n",
       "      <td>0.266256</td>\n",
       "      <td>0.306442</td>\n",
       "      <td>0.302679</td>\n",
       "      <td>0.278631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.289138</td>\n",
       "      <td>0.342741</td>\n",
       "      <td>0.404779</td>\n",
       "      <td>0.332403</td>\n",
       "      <td>0.404835</td>\n",
       "      <td>0.353729</td>\n",
       "      <td>0.355685</td>\n",
       "      <td>0.298864</td>\n",
       "      <td>0.338066</td>\n",
       "      <td>0.351576</td>\n",
       "      <td>0.287417</td>\n",
       "      <td>0.275774</td>\n",
       "      <td>0.301989</td>\n",
       "      <td>0.322541</td>\n",
       "      <td>0.330022</td>\n",
       "      <td>0.308059</td>\n",
       "      <td>0.324033</td>\n",
       "      <td>0.336096</td>\n",
       "      <td>0.333953</td>\n",
       "      <td>0.339164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.345989</td>\n",
       "      <td>0.448711</td>\n",
       "      <td>0.423472</td>\n",
       "      <td>0.470876</td>\n",
       "      <td>0.453521</td>\n",
       "      <td>0.486584</td>\n",
       "      <td>0.469274</td>\n",
       "      <td>0.450487</td>\n",
       "      <td>0.511284</td>\n",
       "      <td>0.555632</td>\n",
       "      <td>0.465398</td>\n",
       "      <td>0.474768</td>\n",
       "      <td>0.530432</td>\n",
       "      <td>0.430571</td>\n",
       "      <td>0.325667</td>\n",
       "      <td>0.283553</td>\n",
       "      <td>0.418775</td>\n",
       "      <td>0.544261</td>\n",
       "      <td>0.392954</td>\n",
       "      <td>0.455828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.279709</td>\n",
       "      <td>0.279404</td>\n",
       "      <td>0.271222</td>\n",
       "      <td>0.255758</td>\n",
       "      <td>0.271182</td>\n",
       "      <td>0.299308</td>\n",
       "      <td>0.290421</td>\n",
       "      <td>0.306409</td>\n",
       "      <td>0.315121</td>\n",
       "      <td>0.323668</td>\n",
       "      <td>0.299322</td>\n",
       "      <td>0.323019</td>\n",
       "      <td>0.314338</td>\n",
       "      <td>0.306716</td>\n",
       "      <td>0.293471</td>\n",
       "      <td>0.332901</td>\n",
       "      <td>0.306540</td>\n",
       "      <td>0.346105</td>\n",
       "      <td>0.310145</td>\n",
       "      <td>0.279055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6121</th>\n",
       "      <td>0.281047</td>\n",
       "      <td>0.381089</td>\n",
       "      <td>0.294996</td>\n",
       "      <td>0.325468</td>\n",
       "      <td>0.269447</td>\n",
       "      <td>0.302485</td>\n",
       "      <td>0.321952</td>\n",
       "      <td>0.338515</td>\n",
       "      <td>0.330786</td>\n",
       "      <td>0.332235</td>\n",
       "      <td>0.325957</td>\n",
       "      <td>0.341718</td>\n",
       "      <td>0.370853</td>\n",
       "      <td>0.349132</td>\n",
       "      <td>0.315105</td>\n",
       "      <td>0.331168</td>\n",
       "      <td>0.255325</td>\n",
       "      <td>0.350236</td>\n",
       "      <td>0.331681</td>\n",
       "      <td>0.291180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6122</th>\n",
       "      <td>0.315737</td>\n",
       "      <td>0.417186</td>\n",
       "      <td>0.396996</td>\n",
       "      <td>0.431619</td>\n",
       "      <td>0.387378</td>\n",
       "      <td>0.343018</td>\n",
       "      <td>0.334033</td>\n",
       "      <td>0.309258</td>\n",
       "      <td>0.264605</td>\n",
       "      <td>0.275893</td>\n",
       "      <td>0.292067</td>\n",
       "      <td>0.303008</td>\n",
       "      <td>0.299297</td>\n",
       "      <td>0.244454</td>\n",
       "      <td>0.345349</td>\n",
       "      <td>0.346187</td>\n",
       "      <td>0.402121</td>\n",
       "      <td>0.368957</td>\n",
       "      <td>0.369427</td>\n",
       "      <td>0.371170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6123</th>\n",
       "      <td>0.321987</td>\n",
       "      <td>0.368787</td>\n",
       "      <td>0.388510</td>\n",
       "      <td>0.342703</td>\n",
       "      <td>0.290869</td>\n",
       "      <td>0.288450</td>\n",
       "      <td>0.294044</td>\n",
       "      <td>0.251566</td>\n",
       "      <td>0.230054</td>\n",
       "      <td>0.228419</td>\n",
       "      <td>0.279573</td>\n",
       "      <td>0.239603</td>\n",
       "      <td>0.270655</td>\n",
       "      <td>0.247639</td>\n",
       "      <td>0.254388</td>\n",
       "      <td>0.267771</td>\n",
       "      <td>0.283404</td>\n",
       "      <td>0.263427</td>\n",
       "      <td>0.283208</td>\n",
       "      <td>0.275230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6124</th>\n",
       "      <td>0.339570</td>\n",
       "      <td>0.393034</td>\n",
       "      <td>0.389208</td>\n",
       "      <td>0.316327</td>\n",
       "      <td>0.318563</td>\n",
       "      <td>0.323392</td>\n",
       "      <td>0.313922</td>\n",
       "      <td>0.350479</td>\n",
       "      <td>0.342351</td>\n",
       "      <td>0.354453</td>\n",
       "      <td>0.348601</td>\n",
       "      <td>0.348120</td>\n",
       "      <td>0.325923</td>\n",
       "      <td>0.291070</td>\n",
       "      <td>0.322698</td>\n",
       "      <td>0.365566</td>\n",
       "      <td>0.328706</td>\n",
       "      <td>0.354871</td>\n",
       "      <td>0.353378</td>\n",
       "      <td>0.326281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6125</th>\n",
       "      <td>0.312823</td>\n",
       "      <td>0.286443</td>\n",
       "      <td>0.420375</td>\n",
       "      <td>0.247617</td>\n",
       "      <td>0.264243</td>\n",
       "      <td>0.259355</td>\n",
       "      <td>0.268153</td>\n",
       "      <td>0.263015</td>\n",
       "      <td>0.246574</td>\n",
       "      <td>0.224854</td>\n",
       "      <td>0.251679</td>\n",
       "      <td>0.237429</td>\n",
       "      <td>0.270217</td>\n",
       "      <td>0.244477</td>\n",
       "      <td>0.222471</td>\n",
       "      <td>0.230471</td>\n",
       "      <td>0.201343</td>\n",
       "      <td>0.224726</td>\n",
       "      <td>0.230734</td>\n",
       "      <td>0.221677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6126 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      NDVI_2000  NDVI_2001  NDVI_2002  NDVI_2003  NDVI_2004  NDVI_2005  \\\n",
       "0      0.520041   0.441816   0.590909   0.567321   0.520761   0.598021   \n",
       "1      0.255850   0.251777   0.233125   0.240606   0.259371   0.267388   \n",
       "2      0.289138   0.342741   0.404779   0.332403   0.404835   0.353729   \n",
       "3      0.345989   0.448711   0.423472   0.470876   0.453521   0.486584   \n",
       "4      0.279709   0.279404   0.271222   0.255758   0.271182   0.299308   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "6121   0.281047   0.381089   0.294996   0.325468   0.269447   0.302485   \n",
       "6122   0.315737   0.417186   0.396996   0.431619   0.387378   0.343018   \n",
       "6123   0.321987   0.368787   0.388510   0.342703   0.290869   0.288450   \n",
       "6124   0.339570   0.393034   0.389208   0.316327   0.318563   0.323392   \n",
       "6125   0.312823   0.286443   0.420375   0.247617   0.264243   0.259355   \n",
       "\n",
       "      NDVI_2006  NDVI_2007  NDVI_2008  NDVI_2009  NDVI_2010  NDVI_2011  \\\n",
       "0      0.576371   0.529067   0.572539   0.531320   0.536898   0.606290   \n",
       "1      0.256132   0.301995   0.317402   0.264193   0.283245   0.275672   \n",
       "2      0.355685   0.298864   0.338066   0.351576   0.287417   0.275774   \n",
       "3      0.469274   0.450487   0.511284   0.555632   0.465398   0.474768   \n",
       "4      0.290421   0.306409   0.315121   0.323668   0.299322   0.323019   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "6121   0.321952   0.338515   0.330786   0.332235   0.325957   0.341718   \n",
       "6122   0.334033   0.309258   0.264605   0.275893   0.292067   0.303008   \n",
       "6123   0.294044   0.251566   0.230054   0.228419   0.279573   0.239603   \n",
       "6124   0.313922   0.350479   0.342351   0.354453   0.348601   0.348120   \n",
       "6125   0.268153   0.263015   0.246574   0.224854   0.251679   0.237429   \n",
       "\n",
       "      NDVI_2012  NDVI_2013  NDVI_2014  NDVI_2015  NDVI_2016  NDVI_2017  \\\n",
       "0      0.565013   0.535213   0.413766   0.466405   0.614485   0.616926   \n",
       "1      0.302882   0.268858   0.267923   0.286384   0.266256   0.306442   \n",
       "2      0.301989   0.322541   0.330022   0.308059   0.324033   0.336096   \n",
       "3      0.530432   0.430571   0.325667   0.283553   0.418775   0.544261   \n",
       "4      0.314338   0.306716   0.293471   0.332901   0.306540   0.346105   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "6121   0.370853   0.349132   0.315105   0.331168   0.255325   0.350236   \n",
       "6122   0.299297   0.244454   0.345349   0.346187   0.402121   0.368957   \n",
       "6123   0.270655   0.247639   0.254388   0.267771   0.283404   0.263427   \n",
       "6124   0.325923   0.291070   0.322698   0.365566   0.328706   0.354871   \n",
       "6125   0.270217   0.244477   0.222471   0.230471   0.201343   0.224726   \n",
       "\n",
       "      NDVI_2018  NDVI_2019  \n",
       "0      0.554876   0.634924  \n",
       "1      0.302679   0.278631  \n",
       "2      0.333953   0.339164  \n",
       "3      0.392954   0.455828  \n",
       "4      0.310145   0.279055  \n",
       "...         ...        ...  \n",
       "6121   0.331681   0.291180  \n",
       "6122   0.369427   0.371170  \n",
       "6123   0.283208   0.275230  \n",
       "6124   0.353378   0.326281  \n",
       "6125   0.230734   0.221677  \n",
       "\n",
       "[6126 rows x 20 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "0w-EDL3x5Kv5"
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preproc_scaling', StandardScaler()),\n",
    "                 ('lr', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "9KrllZD985eq"
   },
   "outputs": [],
   "source": [
    "parameters = {'lr__C':np.arange(0.1, 1.1, 0.05),\n",
    "             'lr__penalty': ['l1', 'l2', 'elasticnet']}\n",
    "\n",
    "pipe = GridSearchCV(pipe, \n",
    "                    parameters,\n",
    "                    verbose=1,\n",
    "                    cv=KFold(n_splits=5, shuffle=True, random_state=123),\n",
    "                    n_jobs=16,\n",
    "                    #return_train_score=True,\n",
    "                    scoring='f1_macro'                   \n",
    "                    #refit=False\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "amgTj_Im5vJa",
    "outputId": "f2b94fe5-cadd-4e41-f7f3-20fc2db75db1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laia/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "200 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/laia/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/laia/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/laia/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/laia/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/laia/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/laia/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/laia/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/laia/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/laia/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.66109083        nan        nan 0.66083736        nan\n",
      "        nan 0.66043579        nan        nan 0.66009341        nan\n",
      "        nan 0.6598155         nan        nan 0.65983433        nan\n",
      "        nan 0.65939942        nan        nan 0.65969379        nan\n",
      "        nan 0.65987786        nan        nan 0.65952963        nan\n",
      "        nan 0.65934453        nan        nan 0.65934453        nan\n",
      "        nan 0.66005278        nan        nan 0.65989719        nan\n",
      "        nan 0.65970484        nan        nan 0.65970484        nan\n",
      "        nan 0.6595627         nan        nan 0.65970484        nan\n",
      "        nan 0.65956396        nan        nan 0.65957064        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=123, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('preproc_scaling', StandardScaler()),\n",
       "                                       ('lr', LogisticRegression())]),\n",
       "             n_jobs=16,\n",
       "             param_grid={'lr__C': array([0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 , 0.55, 0.6 ,\n",
       "       0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  , 1.05]),\n",
       "                         'lr__penalty': ['l1', 'l2', 'elasticnet']},\n",
       "             scoring='f1_macro', verbose=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/cv_lr.joblib']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(pipe, './models/cv_lr.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8QSIgU821vsP",
    "outputId": "30afcf05-f778-4406-f270-b2f0e899128a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preproc_scaling', StandardScaler()),\n",
       "                ('lr', LogisticRegression(C=0.1))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D4KkuusE1yZN",
    "outputId": "38aead74-7b0b-4219-df3f-863e87efb94f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr__C': 0.1, 'lr__penalty': 'l2'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-7BZk8qFA_S8",
    "outputId": "580f2fe4-674c-4c11-bb27-b045ba583d78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6610908330276264"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9oJEXgX5z6u",
    "outputId": "5deb45e2-0f0a-482e-9c98-fde6de26da2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6662441314541846"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test, test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.49      0.52       877\n",
      "           1       0.77      0.77      0.77       900\n",
      "           2       0.67      0.75      0.70       859\n",
      "\n",
      "    accuracy                           0.67      2636\n",
      "   macro avg       0.67      0.67      0.67      2636\n",
      "weighted avg       0.67      0.67      0.67      2636\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test['label'],pipe.best_estimator_.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "PS1YiHdKRVV2"
   },
   "outputs": [],
   "source": [
    "test.to_file(\"data/predictions_reglog.geojson\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
