{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_xKTfvpIzf8g"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from joblib import dump, load\n",
    "import geopandas as gpd\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zfN_yTy1z7Q8"
   },
   "outputs": [],
   "source": [
    "train = gpd.read_file( \"./data/train_data_final.geojson\")\n",
    "test =  gpd.read_file(\"./data/test_data_final.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "7ooSD3Dk0yOY"
   },
   "outputs": [],
   "source": [
    "X = train.loc[:,'NDVI_2000':'NDVI_2019']\n",
    "y = train['label.x']\n",
    "X_test = test.loc[:,'NDVI_2000':'NDVI_2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "0w-EDL3x5Kv5"
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preproc_scaling', StandardScaler()),\n",
    "                 ('lr', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "9KrllZD985eq"
   },
   "outputs": [],
   "source": [
    "parameters = {'lr__C':np.arange(0.1, 1.1, 0.05),\n",
    "             'lr__penalty': ['l1', 'l2', 'elasticnet']}\n",
    "\n",
    "pipe = GridSearchCV(pipe, \n",
    "                    parameters,\n",
    "                    verbose=1,\n",
    "                    cv=KFold(n_splits=5, shuffle=True, random_state=123),\n",
    "                    n_jobs=16,\n",
    "                    #return_train_score=True,\n",
    "                    scoring='f1_macro'                   \n",
    "                    #refit=False\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "amgTj_Im5vJa",
    "outputId": "f2b94fe5-cadd-4e41-f7f3-20fc2db75db1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laia/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "200 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/laia/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/laia/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/laia/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/laia/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/laia/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/laia/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/laia/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/laia/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/laia/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.66060568        nan        nan 0.65926715        nan\n",
      "        nan 0.66020877        nan        nan 0.66057274        nan\n",
      "        nan 0.66077194        nan        nan 0.66111104        nan\n",
      "        nan 0.66089618        nan        nan 0.6606066         nan\n",
      "        nan 0.66046487        nan        nan 0.66033452        nan\n",
      "        nan 0.66052409        nan        nan 0.66052409        nan\n",
      "        nan 0.66055928        nan        nan 0.66044469        nan\n",
      "        nan 0.66012093        nan        nan 0.66049441        nan\n",
      "        nan 0.66050532        nan        nan 0.66050532        nan\n",
      "        nan 0.66050532        nan        nan 0.66050268        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=123, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('preproc_scaling', StandardScaler()),\n",
       "                                       ('lr', LogisticRegression())]),\n",
       "             n_jobs=16,\n",
       "             param_grid={'lr__C': array([0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 , 0.55, 0.6 ,\n",
       "       0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  , 1.05]),\n",
       "                         'lr__penalty': ['l1', 'l2', 'elasticnet']},\n",
       "             scoring='f1_macro', verbose=1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/cv_lr.joblib']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(pipe, './models/cv_lr.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8QSIgU821vsP",
    "outputId": "30afcf05-f778-4406-f270-b2f0e899128a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preproc_scaling', StandardScaler()),\n",
       "                ('lr', LogisticRegression(C=0.3500000000000001))])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D4KkuusE1yZN",
    "outputId": "38aead74-7b0b-4219-df3f-863e87efb94f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr__C': 0.3500000000000001, 'lr__penalty': 'l2'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-7BZk8qFA_S8",
    "outputId": "580f2fe4-674c-4c11-bb27-b045ba583d78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6611110386794122"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9oJEXgX5z6u",
    "outputId": "5deb45e2-0f0a-482e-9c98-fde6de26da2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6640504270689774"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test, test.label_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "PS1YiHdKRVV2"
   },
   "outputs": [],
   "source": [
    "test.to_file(\"data/predictions_reglog.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
